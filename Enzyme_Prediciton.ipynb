{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Machine Learning Algorithms to Determine Enzyme Producitivty"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We were provided raw experimental data and converted it into an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methanol (co-solvent) concentration increases sequentially with substrate concentration\n",
    "experiment_1 = {\n",
    "    'Initial_Sustrate_Conc': [1, 2, 3, 4, 5, 6],\n",
    "    'MeOH_Conc': [5.00, 10.00, 15.00, 20.00, 25.00, 30.00],\n",
    "    'Substrate_Peark_Area': [239089, 92407, 760705, 13824260, 34420970, 77037347],\n",
    "    'Final_Substrate_Conc': [0.0, 0.0, 0.0, 1.1, 2.7, 6.1],\n",
    "    'Product_Peark_Area': [27499017, 2935589, 8279794, 57339935, 55667538, 7119932],\n",
    "    'Final_Product_Conc': [1.490, 0.092, 0.396, 3.189, 3.093, 0.330],\n",
    "    'Conversion_Rate': [101.56, 101.37, 99.13, 73.23, 45.63, -2.11],\n",
    "    'Productivity': [149.01, 4.60, 13.21, 79.71, 61.87, 5.50]\n",
    "}\n",
    "\n",
    "# Control the concentration of methanol in the reaction system 20%\n",
    "experiment_2 = {\n",
    "    'Initial_Sustrate_Conc': [1, 2, 3, 4, 5, 6],\n",
    "    'Substrate_Peark_Area': [5419363, 15003082, 25689744, 36346425, 15051326, 27505398],\n",
    "    'Final_Substrate_Conc': [0.4, 1.2, 2.0, 2.9, 1.2, 2.2],\n",
    "    'Product_Peark_Area': [7538350, 18260347, 18260347, 18260347, 18361504, 26877435],\n",
    "    'Final_Product_Conc': [0.354, 0.964, 1.223, 1.576, 0.970, 1.455],\n",
    "    'Conversion_Rate': [60.13, 41.74, 32.67, 28.19, 76.62, 63.91],\n",
    "    'Productivity': [35.40, 48.21, 40.77, 39.41, 19.40, 24.25],\n",
    "    'MeOH_Conc': [20] * 6\n",
    "}\n",
    "\n",
    "# Increase the proportion of enzymes in the reaction system\n",
    "experiment_3 = {\n",
    "    'Enzyme_Addition': [10, 10, 10, 10, 10, 10, 15, 15, 15, 15, 15, 15, 30, 30, 30, 30, 30, 30, 45, 45, 45, 45, 45, 45, 60, 60, 60, 60, 60, 60],\n",
    "    'Initial_Substrate_Conc': [1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6],\n",
    "    'Final_Substrate_Conc': [0.6, 1.4, 2.6, 2.0, 0.9, 0.8, 0.8, 1.7, 2.7, 3.2, 3.6, 3.4, 0.5, 1.3, 2.5, 3.0, 3.4, 2.8, 0.3, 1.0, 2.2, 2.6, 3.0, 2.7, 0.5, 1.2, 2.2, 2.6, 3.0, 2.3],\n",
    "    'Final_Product_Conc': [0.319, 0.456, 0.557, 0.425, 0.196, 0.196, 0.120, 0.188, 0.432, 0.395, 0.566, 0.576, 0.387, 0.554, 0.792, 0.853, 0.991, 1.161, 0.544, 0.819, 0.885, 1.241, 1.161, 1.303, 0.275, 0.485, 0.995, 1.201, 1.322, 1.072],\n",
    "    'Conversion_Rate': [42.42, 32.33, 12.45, 50.5, 82.15, 86.93, 21.34, 16.10, 9.03, 18.89, 28.54, 43.08, 48.74, 35.33, 16.01, 24.57, 31.96, 53.34, 69.27, 50.18, 27.64, 35.55, 40.46, 55.03, 53.81, 41.58, 25.54, 35.47, 40.75, 61.97],\n",
    "    'Productivity': [31.86, 22.78, 18.55, 10.63, 3.93, 3.27, 11.98, 9.40, 14.39, 9.88, 11.33, 9.61, 38.73, 27.70, 26.39, 21.33, 19.81, 13.75, 54.4, 40.93, 29.49, 31.03, 23.23, 21.71, 27.52, 24.27, 33.17, 30.03, 26.43, 17.87],\n",
    "    'MeOH_Conc': [20] * 30\n",
    "}\n",
    "\n",
    "# Optimization of reaction pH\n",
    "experiment_4 = {\n",
    "    'pH': [3, 4, 5, 6, 7, 8],\n",
    "    'Initial_Substrate_Conc': [2, 2, 2, 2, 2, 2],\n",
    "    'Final_Substrate_Conc': [1.181, 0.597, 0.32, 0.944, 1.572, 1.942],\n",
    "    'Final_Product_Conc': [0.731, 1.394, 1.666, 1.037, 0.408, 0.017],\n",
    "    'Conversion_Rate':[40.95, 70.15, 84.00, 52.80, 21.40, 2.90],\n",
    "    'Productivity':[36.55, 69.70, 83.30, 51.85, 20.40, 0.85]\n",
    "}\n",
    "\n",
    "# Optimization of reaction temperature\n",
    "experiment_5 = {\n",
    "    'Temperature': [20, 30, 40, 50 , 60, 70],\n",
    "    'Initial_Substrate_Conc': [2, 2, 2, 2, 2, 2],\n",
    "    'Final_Substrate_Conc': [0.997, 0.863, 0.491, 0.352, 0.988, 1.921],\n",
    "    'Final_Product_Conc': [0.969, 1.122, 1.428, 1.632, 0.986, 0.051],\n",
    "    'Conversion_Rate':[50.15, 56.85, 75.45, 82.40, 50.60, 3.95],\n",
    "    'Productivity':[48.45, 56.10, 71.40, 81.60, 49.30, 2.55]\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert them into a data frame for easier analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.DataFrame(experiment_1)\n",
    "df2 = pd.DataFrame(experiment_2)\n",
    "df3 = pd.DataFrame(experiment_3)\n",
    "df4 = pd.DataFrame(experiment_4)\n",
    "df5 = pd.DataFrame(experiment_5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at Experiment 3 as an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Enzyme_Addition</th>\n",
       "      <td>30.0</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>18.919065</td>\n",
       "      <td>10.00</td>\n",
       "      <td>15.0000</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>45.0000</td>\n",
       "      <td>60.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Initial_Substrate_Conc</th>\n",
       "      <td>30.0</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>1.737021</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>3.5000</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>6.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Final_Substrate_Conc</th>\n",
       "      <td>30.0</td>\n",
       "      <td>2.026667</td>\n",
       "      <td>1.017751</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.0500</td>\n",
       "      <td>2.2500</td>\n",
       "      <td>2.7750</td>\n",
       "      <td>3.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Final_Product_Conc</th>\n",
       "      <td>30.0</td>\n",
       "      <td>0.682233</td>\n",
       "      <td>0.374907</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.4025</td>\n",
       "      <td>0.5615</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>1.322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Conversion_Rate</th>\n",
       "      <td>30.0</td>\n",
       "      <td>39.698667</td>\n",
       "      <td>19.293357</td>\n",
       "      <td>9.03</td>\n",
       "      <td>26.0650</td>\n",
       "      <td>38.0050</td>\n",
       "      <td>50.4200</td>\n",
       "      <td>86.930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Productivity</th>\n",
       "      <td>30.0</td>\n",
       "      <td>22.180000</td>\n",
       "      <td>11.537886</td>\n",
       "      <td>3.27</td>\n",
       "      <td>12.4225</td>\n",
       "      <td>22.2450</td>\n",
       "      <td>29.0425</td>\n",
       "      <td>54.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MeOH_Conc</th>\n",
       "      <td>30.0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.00</td>\n",
       "      <td>20.0000</td>\n",
       "      <td>20.0000</td>\n",
       "      <td>20.0000</td>\n",
       "      <td>20.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        count       mean        std    min      25%      50%  \\\n",
       "Enzyme_Addition          30.0  32.000000  18.919065  10.00  15.0000  30.0000   \n",
       "Initial_Substrate_Conc   30.0   3.500000   1.737021   1.00   2.0000   3.5000   \n",
       "Final_Substrate_Conc     30.0   2.026667   1.017751   0.30   1.0500   2.2500   \n",
       "Final_Product_Conc       30.0   0.682233   0.374907   0.12   0.4025   0.5615   \n",
       "Conversion_Rate          30.0  39.698667  19.293357   9.03  26.0650  38.0050   \n",
       "Productivity             30.0  22.180000  11.537886   3.27  12.4225  22.2450   \n",
       "MeOH_Conc                30.0  20.000000   0.000000  20.00  20.0000  20.0000   \n",
       "\n",
       "                            75%     max  \n",
       "Enzyme_Addition         45.0000  60.000  \n",
       "Initial_Substrate_Conc   5.0000   6.000  \n",
       "Final_Substrate_Conc     2.7750   3.600  \n",
       "Final_Product_Conc       0.9940   1.322  \n",
       "Conversion_Rate         50.4200  86.930  \n",
       "Productivity            29.0425  54.400  \n",
       "MeOH_Conc               20.0000  20.000  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return basic statistics of the dataframe\n",
    "df3.describe().T"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at more detailed information about the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30 entries, 0 to 29\n",
      "Data columns (total 7 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   Enzyme_Addition         30 non-null     int64  \n",
      " 1   Initial_Substrate_Conc  30 non-null     int64  \n",
      " 2   Final_Substrate_Conc    30 non-null     float64\n",
      " 3   Final_Product_Conc      30 non-null     float64\n",
      " 4   Conversion_Rate         30 non-null     float64\n",
      " 5   Productivity            30 non-null     float64\n",
      " 6   MeOH_Conc               30 non-null     int64  \n",
      "dtypes: float64(4), int64(3)\n",
      "memory usage: 1.8 KB\n"
     ]
    }
   ],
   "source": [
    "df3.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert all values into aa float to be more consistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df3.astype(float)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering the small amount of data points, dummy data will be created based from the mean and the standard deviation from a normal curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Get the mean and standard deviation of each column in the data frame\n",
    "df3_means = df3.mean()\n",
    "df3_stdv = df3.std()\n",
    "\n",
    "# Declare the amount of dummy data to be created\n",
    "num_of_samples = 1000\n",
    "\n",
    "output_data ={}\n",
    "\n",
    "# Declare a new array to hold the dummy data\n",
    "for col in df3.columns:\n",
    "    output_data[col] = np.random.normal(loc = df3_means[col], scale = df3_stdv[col], size = num_of_samples)\n",
    "\n",
    "# Create a new data frame with the dummy data\n",
    "df3_Dummy = pd.DataFrame(output_data)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the statistics of the dummy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Enzyme_Addition</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>31.769087</td>\n",
       "      <td>19.284269</td>\n",
       "      <td>-36.753570</td>\n",
       "      <td>18.753225</td>\n",
       "      <td>32.085516</td>\n",
       "      <td>43.907693</td>\n",
       "      <td>91.743261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Initial_Substrate_Conc</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>3.538589</td>\n",
       "      <td>1.776081</td>\n",
       "      <td>-2.444930</td>\n",
       "      <td>2.340679</td>\n",
       "      <td>3.553530</td>\n",
       "      <td>4.748303</td>\n",
       "      <td>9.076914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Final_Substrate_Conc</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>2.009464</td>\n",
       "      <td>1.020370</td>\n",
       "      <td>-1.376320</td>\n",
       "      <td>1.327373</td>\n",
       "      <td>1.993916</td>\n",
       "      <td>2.713467</td>\n",
       "      <td>5.080413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Final_Product_Conc</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.667451</td>\n",
       "      <td>0.366123</td>\n",
       "      <td>-0.439257</td>\n",
       "      <td>0.427762</td>\n",
       "      <td>0.673251</td>\n",
       "      <td>0.922775</td>\n",
       "      <td>1.824696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Conversion_Rate</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>40.430086</td>\n",
       "      <td>19.299760</td>\n",
       "      <td>-19.897863</td>\n",
       "      <td>28.079376</td>\n",
       "      <td>40.245707</td>\n",
       "      <td>53.487325</td>\n",
       "      <td>110.513509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Productivity</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>22.063253</td>\n",
       "      <td>11.332868</td>\n",
       "      <td>-11.399866</td>\n",
       "      <td>14.194980</td>\n",
       "      <td>22.100774</td>\n",
       "      <td>29.640014</td>\n",
       "      <td>57.458275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MeOH_Conc</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         count       mean        std        min        25%  \\\n",
       "Enzyme_Addition         1000.0  31.769087  19.284269 -36.753570  18.753225   \n",
       "Initial_Substrate_Conc  1000.0   3.538589   1.776081  -2.444930   2.340679   \n",
       "Final_Substrate_Conc    1000.0   2.009464   1.020370  -1.376320   1.327373   \n",
       "Final_Product_Conc      1000.0   0.667451   0.366123  -0.439257   0.427762   \n",
       "Conversion_Rate         1000.0  40.430086  19.299760 -19.897863  28.079376   \n",
       "Productivity            1000.0  22.063253  11.332868 -11.399866  14.194980   \n",
       "MeOH_Conc               1000.0  20.000000   0.000000  20.000000  20.000000   \n",
       "\n",
       "                              50%        75%         max  \n",
       "Enzyme_Addition         32.085516  43.907693   91.743261  \n",
       "Initial_Substrate_Conc   3.553530   4.748303    9.076914  \n",
       "Final_Substrate_Conc     1.993916   2.713467    5.080413  \n",
       "Final_Product_Conc       0.673251   0.922775    1.824696  \n",
       "Conversion_Rate         40.245707  53.487325  110.513509  \n",
       "Productivity            22.100774  29.640014   57.458275  \n",
       "MeOH_Conc               20.000000  20.000000   20.000000  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3_Dummy.describe().T"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the Conversion_Rate and the Productivity were randomly generated, in reality they are calculations that will represent the target 'Result'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the columns\n",
    "df3_Dummy = df3_Dummy.drop(columns = ['Conversion_Rate', 'Productivity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Calculated Conversion Rate Column\n",
    "df3_Dummy['Calc_Conversion_Rate'] = (df3_Dummy['Initial_Substrate_Conc'] - df3_Dummy['Final_Substrate_Conc']) / df3_Dummy['Initial_Substrate_Conc']\n",
    "\n",
    "# Add Calculated Productivity Column\n",
    "df3_Dummy['Calc_Productivity'] = df3_Dummy['Final_Product_Conc'] / df3_Dummy['Initial_Substrate_Conc']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove any undefined expressions or NaN values that could be generated by the calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Enzyme_Addition</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>31.769087</td>\n",
       "      <td>19.284269</td>\n",
       "      <td>-36.753570</td>\n",
       "      <td>18.753225</td>\n",
       "      <td>32.085516</td>\n",
       "      <td>43.907693</td>\n",
       "      <td>91.743261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Initial_Substrate_Conc</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>3.538589</td>\n",
       "      <td>1.776081</td>\n",
       "      <td>-2.444930</td>\n",
       "      <td>2.340679</td>\n",
       "      <td>3.553530</td>\n",
       "      <td>4.748303</td>\n",
       "      <td>9.076914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Final_Substrate_Conc</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>2.009464</td>\n",
       "      <td>1.020370</td>\n",
       "      <td>-1.376320</td>\n",
       "      <td>1.327373</td>\n",
       "      <td>1.993916</td>\n",
       "      <td>2.713467</td>\n",
       "      <td>5.080413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Final_Product_Conc</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.667451</td>\n",
       "      <td>0.366123</td>\n",
       "      <td>-0.439257</td>\n",
       "      <td>0.427762</td>\n",
       "      <td>0.673251</td>\n",
       "      <td>0.922775</td>\n",
       "      <td>1.824696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Calc_Conversion_Rate</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.317044</td>\n",
       "      <td>2.795689</td>\n",
       "      <td>-20.179370</td>\n",
       "      <td>0.109479</td>\n",
       "      <td>0.442517</td>\n",
       "      <td>0.667983</td>\n",
       "      <td>45.349706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Calc_Productivity</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.276522</td>\n",
       "      <td>1.384519</td>\n",
       "      <td>-13.686697</td>\n",
       "      <td>0.102741</td>\n",
       "      <td>0.182730</td>\n",
       "      <td>0.304585</td>\n",
       "      <td>31.708026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         count       mean        std        min        25%  \\\n",
       "Enzyme_Addition         1000.0  31.769087  19.284269 -36.753570  18.753225   \n",
       "Initial_Substrate_Conc  1000.0   3.538589   1.776081  -2.444930   2.340679   \n",
       "Final_Substrate_Conc    1000.0   2.009464   1.020370  -1.376320   1.327373   \n",
       "Final_Product_Conc      1000.0   0.667451   0.366123  -0.439257   0.427762   \n",
       "Calc_Conversion_Rate    1000.0   0.317044   2.795689 -20.179370   0.109479   \n",
       "Calc_Productivity       1000.0   0.276522   1.384519 -13.686697   0.102741   \n",
       "\n",
       "                              50%        75%        max  \n",
       "Enzyme_Addition         32.085516  43.907693  91.743261  \n",
       "Initial_Substrate_Conc   3.553530   4.748303   9.076914  \n",
       "Final_Substrate_Conc     1.993916   2.713467   5.080413  \n",
       "Final_Product_Conc       0.673251   0.922775   1.824696  \n",
       "Calc_Conversion_Rate     0.442517   0.667983  45.349706  \n",
       "Calc_Productivity        0.182730   0.304585  31.708026  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting undefined values as NaN\n",
    "df3_Dummy.replace(-float('inf'), np.nan, inplace = True)\n",
    "df3_Dummy.replace(float('inf'), np.nan, inplace = True)\n",
    "\n",
    "# Dropping NaN\n",
    "df3_Dummy.dropna(inplace = True)\n",
    "\n",
    "# We will also remove MeOH_Conc because it stays constant throghout the experiment\n",
    "df3_Dummy.drop(columns = ['MeOH_Conc'], inplace = True)\n",
    "\n",
    "df3_Dummy.describe().T"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A new Rating column was created based on the sum of the conversion rate and the productivity. This gives us a better represntation of how well the enzyme worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depending ont the conversion rate and productivity, the output value for Rating changes\n",
    "df3_Dummy['conversion'] = (df3_Dummy['Calc_Conversion_Rate']*0.5) + (df3_Dummy['Calc_Productivity']*0.5)\n",
    "\n",
    "# Method to return an integer value between 1 - 10 depending on the percentage out of 100\n",
    "def get_rating(x):\n",
    "    rating = int((x/100)*10) + 1\n",
    "    return min(max(rating, 1), 10)\n",
    "\n",
    "# Applying the method above to generate random ratings based off the Conversion Rate & Productivity columns onto the final version of the dataframe\n",
    "df3_Final = df3_Dummy.copy()\n",
    "df3_Final['Rating'] = df3_Dummy['conversion'].apply(get_rating)\n",
    "\n",
    "# We do not need the calculations anymore so they will be removed from the dataframe\n",
    "# df3_Final.drop(columns = ['Calc_Conversion_Rate', 'Calc_Productivity', 'conversion'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Enzyme_Addition</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>31.769087</td>\n",
       "      <td>19.284269</td>\n",
       "      <td>-36.753570</td>\n",
       "      <td>18.753225</td>\n",
       "      <td>32.085516</td>\n",
       "      <td>43.907693</td>\n",
       "      <td>91.743261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Initial_Substrate_Conc</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>3.538589</td>\n",
       "      <td>1.776081</td>\n",
       "      <td>-2.444930</td>\n",
       "      <td>2.340679</td>\n",
       "      <td>3.553530</td>\n",
       "      <td>4.748303</td>\n",
       "      <td>9.076914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Final_Substrate_Conc</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>2.009464</td>\n",
       "      <td>1.020370</td>\n",
       "      <td>-1.376320</td>\n",
       "      <td>1.327373</td>\n",
       "      <td>1.993916</td>\n",
       "      <td>2.713467</td>\n",
       "      <td>5.080413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Final_Product_Conc</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.667451</td>\n",
       "      <td>0.366123</td>\n",
       "      <td>-0.439257</td>\n",
       "      <td>0.427762</td>\n",
       "      <td>0.673251</td>\n",
       "      <td>0.922775</td>\n",
       "      <td>1.824696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Calc_Conversion_Rate</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.317044</td>\n",
       "      <td>2.795689</td>\n",
       "      <td>-20.179370</td>\n",
       "      <td>0.109479</td>\n",
       "      <td>0.442517</td>\n",
       "      <td>0.667983</td>\n",
       "      <td>45.349706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Calc_Productivity</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.276522</td>\n",
       "      <td>1.384519</td>\n",
       "      <td>-13.686697</td>\n",
       "      <td>0.102741</td>\n",
       "      <td>0.182730</td>\n",
       "      <td>0.304585</td>\n",
       "      <td>31.708026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conversion</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.296783</td>\n",
       "      <td>1.064215</td>\n",
       "      <td>-7.952429</td>\n",
       "      <td>0.178355</td>\n",
       "      <td>0.309533</td>\n",
       "      <td>0.422527</td>\n",
       "      <td>15.921710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rating</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>1.004000</td>\n",
       "      <td>0.063151</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         count       mean        std        min        25%  \\\n",
       "Enzyme_Addition         1000.0  31.769087  19.284269 -36.753570  18.753225   \n",
       "Initial_Substrate_Conc  1000.0   3.538589   1.776081  -2.444930   2.340679   \n",
       "Final_Substrate_Conc    1000.0   2.009464   1.020370  -1.376320   1.327373   \n",
       "Final_Product_Conc      1000.0   0.667451   0.366123  -0.439257   0.427762   \n",
       "Calc_Conversion_Rate    1000.0   0.317044   2.795689 -20.179370   0.109479   \n",
       "Calc_Productivity       1000.0   0.276522   1.384519 -13.686697   0.102741   \n",
       "conversion              1000.0   0.296783   1.064215  -7.952429   0.178355   \n",
       "Rating                  1000.0   1.004000   0.063151   1.000000   1.000000   \n",
       "\n",
       "                              50%        75%        max  \n",
       "Enzyme_Addition         32.085516  43.907693  91.743261  \n",
       "Initial_Substrate_Conc   3.553530   4.748303   9.076914  \n",
       "Final_Substrate_Conc     1.993916   2.713467   5.080413  \n",
       "Final_Product_Conc       0.673251   0.922775   1.824696  \n",
       "Calc_Conversion_Rate     0.442517   0.667983  45.349706  \n",
       "Calc_Productivity        0.182730   0.304585  31.708026  \n",
       "conversion               0.309533   0.422527  15.921710  \n",
       "Rating                   1.000000   1.000000   2.000000  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3_Final.describe().T"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can perform a train test split and apply different machine learning models to determine which model can best fit the simulated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Splitting into train and test sets\n",
    "X = df3_Final.loc[:,df3_Final.columns != 'Rating']     \n",
    "y = df3_Final['Rating']  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train = pd.DataFrame(scaler.transform(X_train), columns = X_train.columns)\n",
    "X_test = pd.DataFrame(scaler.transform(X_test), columns = X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression\n",
      "Training set:50.72%\n",
      "Test set:89.27%\n",
      "Mean Cross-Validation Score:0.27\n",
      "----------------------------------------\n",
      "Random Forest Regressor\n",
      "Training set:96.99%\n",
      "Test set:98.02%\n",
      "Mean Cross-Validation Score:0.30\n",
      "----------------------------------------\n",
      "K-Nearest Neighbor\n",
      "Training set:63.91%\n",
      "Test set:63.64%\n",
      "Mean Cross-Validation Score:0.94\n",
      "----------------------------------------\n",
      "Decision Tree Regressor\n",
      "Training set:100.00%\n",
      "Test set:100.00%\n",
      "Mean Cross-Validation Score:0.80\n",
      "----------------------------------------\n",
      "Support Vector Regression\n",
      "Training set:-117.53%\n",
      "Test set:-23.61%\n",
      "Mean Cross-Validation Score:-0.39\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, ShuffleSplit, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import svm\n",
    "\n",
    "cv = ShuffleSplit(n_splits = 10, test_size = 0.2)\n",
    "\n",
    "#Linear Regression\n",
    "model1 = LinearRegression()\n",
    "model1.fit(X_train, y_train)\n",
    "cross_val_scores1 = cross_val_score(model1, X_train, y_train, cv = cv)\n",
    "train_accuracy1 = model1.score(X_train, y_train)\n",
    "test_accuracy1 = model1.score(X_test, y_test)\n",
    "\n",
    "#Random Forest\n",
    "model2 = RandomForestRegressor(random_state = True, warm_start = True, criterion = 'absolute_error', max_depth = 100)\n",
    "model2.fit(X_train, y_train)\n",
    "cross_val_scores2 = cross_val_score(model2, X_train, y_train, cv = cv)\n",
    "train_accuracy2 = model2.score(X_train, y_train)\n",
    "test_accuracy2 = model2.score(X_test, y_test)\n",
    "\n",
    "#KNN\n",
    "model3 =KNeighborsRegressor()\n",
    "model3.fit(X_train, y_train)\n",
    "cross_val_scores3 = cross_val_score(model3, X_train, y_train, cv = cv)\n",
    "train_accuracy3 = model3.score(X_train, y_train)\n",
    "test_accuracy3 = model3.score(X_test, y_test)\n",
    "\n",
    "#Decision Tree\n",
    "model4 = DecisionTreeRegressor()\n",
    "model4.fit(X_train, y_train)\n",
    "cross_val_scores4 = cross_val_score(model4, X_train, y_train, cv = cv)\n",
    "train_accuracy4 = model4.score(X_train, y_train)\n",
    "test_accuracy4 = model4.score(X_test, y_test)\n",
    "\n",
    "#SVR\n",
    "model5 = svm.SVR()\n",
    "model5.fit(X_train, y_train)\n",
    "cross_val_scores5 = cross_val_score(model5, X_train, y_train, cv = cv)\n",
    "train_accuracy5 = model5.score(X_train, y_train)\n",
    "test_accuracy5 = model5.score(X_test, y_test)\n",
    "\n",
    "#Printing Results\n",
    "print(f'Linear Regression\\nTraining set:{100 * train_accuracy1:.2f}%\\nTest set:{100 * test_accuracy1:.2f}%\\nMean Cross-Validation Score:{cross_val_scores1.mean():.2f}')\n",
    "print('----------------------------------------')\n",
    "print(f'Random Forest Regressor\\nTraining set:{100 * train_accuracy2:.2f}%\\nTest set:{100 * test_accuracy2:.2f}%\\nMean Cross-Validation Score:{cross_val_scores2.mean():.2f}')\n",
    "print('----------------------------------------')\n",
    "print(f'K-Nearest Neighbor\\nTraining set:{100 * train_accuracy3:.2f}%\\nTest set:{100 * test_accuracy3:.2f}%\\nMean Cross-Validation Score:{cross_val_scores3.mean():.2f}')\n",
    "print('----------------------------------------')\n",
    "print(f'Decision Tree Regressor\\nTraining set:{100 * train_accuracy4:.2f}%\\nTest set:{100 * test_accuracy4:.2f}%\\nMean Cross-Validation Score:{cross_val_scores4.mean():.2f}')\n",
    "print('----------------------------------------')\n",
    "print(f'Support Vector Regression\\nTraining set:{100 * train_accuracy5:.2f}%\\nTest set:{100 * test_accuracy5:.2f}%\\nMean Cross-Validation Score:{cross_val_scores5.mean():.2f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the predictions of the different models when given the same parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.06044343]\n",
      "[1.86]\n",
      "[1.4]\n",
      "[2.]\n",
      "[1.18083182]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:464: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:464: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:464: UserWarning: X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:464: UserWarning: X does not have valid feature names, but DecisionTreeRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:464: UserWarning: X does not have valid feature names, but SVR was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "result = model1.predict([[10 ,1, 0.6, 0.32, 50, 50, 50]])\n",
    "print(result)\n",
    "result = model2.predict([[10 ,1, 0.6, 0.32, 50, 50, 50]])\n",
    "print(result)\n",
    "result = model3.predict([[10 ,1, 0.6, 0.32, 50, 50, 50]])\n",
    "print(result)\n",
    "result = model4.predict([[10 ,1, 0.6, 0.32, 50, 50, 50]])\n",
    "print(result)\n",
    "result = model5.predict([[10 ,1, 0.6, 0.32, 50, 50, 50]])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Get the mean and standard deviation of each column in the data frame\n",
    "df3_means = df3.mean()\n",
    "df3_stdv = df3.std()\n",
    "\n",
    "# Declare the amount of dummy data to be created\n",
    "num_of_samples = 1000\n",
    "\n",
    "output_data ={}\n",
    "\n",
    "# Declare a new array to hold the dummy data\n",
    "for col in df3.columns:\n",
    "    output_data[col] = np.random.normal(loc = df3_means[col], scale = df3_stdv[col], size = num_of_samples)\n",
    "\n",
    "# Create a new data frame with the dummy data\n",
    "df3_Dummy = pd.DataFrame(output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Calc_Conversion_Rate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/indexes/base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3789\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3790\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3791\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Calc_Conversion_Rate'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 34\u001b[0m\n\u001b[1;32m     31\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(output_data)\n\u001b[1;32m     33\u001b[0m \u001b[39m# Depending ont the conversion rate and productivity, the output value for Rating changes\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mconversion\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m (df[\u001b[39m'\u001b[39;49m\u001b[39mCalc_Conversion_Rate\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m*\u001b[39m \u001b[39m0.5\u001b[39m) \u001b[39m+\u001b[39m (df[\u001b[39m'\u001b[39m\u001b[39mCalc_Productivity\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m*\u001b[39m \u001b[39m0.5\u001b[39m)\n\u001b[1;32m     36\u001b[0m \u001b[39m# Applying the method above to generate random ratings based off the Conversion Rate & Productivity columns onto the final version of the dataframe\u001b[39;00m\n\u001b[1;32m     37\u001b[0m df3_Final \u001b[39m=\u001b[39m df3_Dummy\u001b[39m.\u001b[39mcopy()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/frame.py:3896\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3894\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3895\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3896\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3897\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3898\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/indexes/base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3792\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(casted_key, \u001b[39mslice\u001b[39m) \u001b[39mor\u001b[39;00m (\n\u001b[1;32m   3793\u001b[0m         \u001b[39misinstance\u001b[39m(casted_key, abc\u001b[39m.\u001b[39mIterable)\n\u001b[1;32m   3794\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(x, \u001b[39mslice\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m casted_key)\n\u001b[1;32m   3795\u001b[0m     ):\n\u001b[1;32m   3796\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3797\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3798\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3799\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3800\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Calc_Conversion_Rate'"
     ]
    }
   ],
   "source": [
    "# Method to return an integer value between 1 - 10 depending on the percentage out of 100\n",
    "def get_rating(x):\n",
    "    rating = int((x/100)*10) + 1\n",
    "    return min(max(rating, 1), 10)\n",
    "\n",
    "# Get the mean and standard deviation of each column in the data frame\n",
    "df3_means = df3.mean()\n",
    "df3_stdv = df3.std()\n",
    "\n",
    "# Declare the amount of dummy data to be created\n",
    "num_of_samples = 1000\n",
    "\n",
    "# Number of iterations\n",
    "n = 100\n",
    "\n",
    "# Declare an empty array list\n",
    "output_data ={}\n",
    "\n",
    "accuracy_results = {\n",
    "    'Iteration':[],\n",
    "    'Train_Accuracy':[],\n",
    "    'Test_Accuracy':[],\n",
    "    'Cross-Validation':[]\n",
    "}\n",
    "\n",
    "for i in range(n):\n",
    "    # Declare a new array to hold the dummy data\n",
    "    for col in df3.columns:\n",
    "        output_data[col] = np.random.normal(loc = df3_means[col], scale = df3_stdv[col], size = num_of_samples)\n",
    "    \n",
    "    df = pd.DataFrame(output_data)\n",
    "\n",
    "    # Depending ont the conversion rate and productivity, the output value for Rating changes\n",
    "    df['conversion'] = (df['Calc_Conversion_Rate'] * 0.5) + (df['Calc_Productivity'] * 0.5)\n",
    "\n",
    "    # Applying the method above to generate random ratings based off the Conversion Rate & Productivity columns onto the final version of the dataframe\n",
    "    df3_Final = df3_Dummy.copy()\n",
    "    df3_Final['Rating'] = df3_Dummy['conversion'].apply(get_rating) \n",
    "    \n",
    "    # Split your data into training and testing sets (replace this with your actual data and model)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df3, target_variable, test_size=0.2, random_state=i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
