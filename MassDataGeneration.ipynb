{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase the proportion of enzymes in the reaction system\n",
    "experiment_3 = {\n",
    "    'Enzyme_Addition': [10, 10, 10, 10, 10, 10, 15, 15, 15, 15, 15, 15, 30, 30, 30, 30, 30, 30, 45, 45, 45, 45, 45, 45, 60, 60, 60, 60, 60, 60],\n",
    "    'Initial_Substrate_Conc': [1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6],\n",
    "    'Final_Substrate_Conc': [0.6, 1.4, 2.6, 2.0, 0.9, 0.8, 0.8, 1.7, 2.7, 3.2, 3.6, 3.4, 0.5, 1.3, 2.5, 3.0, 3.4, 2.8, 0.3, 1.0, 2.2, 2.6, 3.0, 2.7, 0.5, 1.2, 2.2, 2.6, 3.0, 2.3],\n",
    "    'Final_Product_Conc': [0.319, 0.456, 0.557, 0.425, 0.196, 0.196, 0.120, 0.188, 0.432, 0.395, 0.566, 0.576, 0.387, 0.554, 0.792, 0.853, 0.991, 1.161, 0.544, 0.819, 0.885, 1.241, 1.161, 1.303, 0.275, 0.485, 0.995, 1.201, 1.322, 1.072],\n",
    "    'Conversion_Rate': [42.42, 32.33, 12.45, 50.5, 82.15, 86.93, 21.34, 16.10, 9.03, 18.89, 28.54, 43.08, 48.74, 35.33, 16.01, 24.57, 31.96, 53.34, 69.27, 50.18, 27.64, 35.55, 40.46, 55.03, 53.81, 41.58, 25.54, 35.47, 40.75, 61.97],\n",
    "    'Productivity': [31.86, 22.78, 18.55, 10.63, 3.93, 3.27, 11.98, 9.40, 14.39, 9.88, 11.33, 9.61, 38.73, 27.70, 26.39, 21.33, 19.81, 13.75, 54.4, 40.93, 29.49, 31.03, 23.23, 21.71, 27.52, 24.27, 33.17, 30.03, 26.43, 17.87],\n",
    "    'MeOH_Conc': [20] * 30\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_exp = pd.DataFrame(experiment_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, ShuffleSplit, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import svm\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Method to return an integer value between 1 - 10 depending on the percentage out of 100\n",
    "def get_rating(x):\n",
    "    rating = int((x/100)*10) + 1\n",
    "    return min(max(rating, 1), 10)\n",
    "\n",
    "# Will return a mult-dimenstional array\n",
    "def GenerateRandomData(number_of_times):\n",
    "    # Get the mean and standard deviation of each column in the data frame\n",
    "    df3_means = df_exp.mean()\n",
    "    df3_stdv = df_exp.std()\n",
    "\n",
    "    output_data ={}\n",
    "\n",
    "    # Declare a new array to hold the dummy data\n",
    "    for col in df_exp.columns:\n",
    "        output_data[col] = np.random.normal(loc = df3_means[col], scale = df3_stdv[col], size = number_of_times)\n",
    "\n",
    "    return output_data\n",
    "\n",
    "def CleanAndCalculateDF(new_df):\n",
    "    # Drop the columns\n",
    "    new_df = new_df.drop(columns = ['Conversion_Rate', 'Productivity'])\n",
    "    # Add Calculated Conversion Rate Column\n",
    "    new_df['Calc_Conversion_Rate'] = (new_df['Initial_Substrate_Conc'] - new_df['Final_Substrate_Conc']) / new_df['Initial_Substrate_Conc']\n",
    "\n",
    "    # Add Calculated Productivity Column\n",
    "    new_df['Calc_Productivity'] = new_df['Final_Product_Conc'] / new_df['Initial_Substrate_Conc']\n",
    "\n",
    "    # Converting undefined values as NaN\n",
    "    new_df.replace(-float('inf'), np.nan, inplace = True)\n",
    "    new_df.replace(float('inf'), np.nan, inplace = True)\n",
    "\n",
    "    # Dropping NaN\n",
    "    new_df.dropna(inplace = True)\n",
    "\n",
    "    # We will also remove MeOH_Conc because it stays constant throghout the experiment\n",
    "    new_df.drop(columns = ['MeOH_Conc'], inplace = True)\n",
    "\n",
    "    # Depending ont the conversion rate and productivity, the output value for Rating changes\n",
    "    new_df['conversion'] = (new_df['Calc_Conversion_Rate']*0.5) + (new_df['Calc_Productivity']*0.5)\n",
    "\n",
    "    # Applying the method above to generate random ratings based off the Conversion Rate & Productivity columns onto the final version of the dataframe\n",
    "    df3_Final = new_df.copy()\n",
    "    df3_Final['Rating'] = new_df['conversion'].apply(get_rating)\n",
    "\n",
    "    return df3_Final\n",
    "\n",
    "def GetToModeling(df):\n",
    "    cv = ShuffleSplit(n_splits = 10, test_size = 0.2)\n",
    "\n",
    "    #Splitting into train and test sets\n",
    "    X = df.loc[:,df.columns != 'Rating']     \n",
    "    y = df['Rating']  \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)\n",
    "\n",
    "    #Linear Regression\n",
    "    model1 = LinearRegression()\n",
    "    model1.fit(X_train, y_train)\n",
    "    cross_val_scores1 = cross_val_score(model1, X_train, y_train, cv = cv)\n",
    "    train_accuracy1 = model1.score(X_train, y_train)\n",
    "    test_accuracy1 = model1.score(X_test, y_test)\n",
    "\n",
    "    #Random Forest\n",
    "    model2 = RandomForestRegressor(random_state = True, warm_start = True, criterion = 'absolute_error', max_depth = 100)\n",
    "    model2.fit(X_train, y_train)\n",
    "    cross_val_scores2 = cross_val_score(model2, X_train, y_train, cv = cv)\n",
    "    train_accuracy2 = model2.score(X_train, y_train)\n",
    "    test_accuracy2 = model2.score(X_test, y_test)\n",
    "\n",
    "    #KNN\n",
    "    model3 =KNeighborsRegressor()\n",
    "    model3.fit(X_train, y_train)\n",
    "    cross_val_scores3 = cross_val_score(model3, X_train, y_train, cv = cv)\n",
    "    train_accuracy3 = model3.score(X_train, y_train)\n",
    "    test_accuracy3 = model3.score(X_test, y_test)\n",
    "\n",
    "    #Decision Tree\n",
    "    model4 = DecisionTreeRegressor()\n",
    "    model4.fit(X_train, y_train)\n",
    "    cross_val_scores4 = cross_val_score(model4, X_train, y_train, cv = cv)\n",
    "    train_accuracy4 = model4.score(X_train, y_train)\n",
    "    test_accuracy4 = model4.score(X_test, y_test)\n",
    "\n",
    "    #SVR\n",
    "    model5 = svm.SVR()\n",
    "    model5.fit(X_train, y_train)\n",
    "    cross_val_scores5 = cross_val_score(model5, X_train, y_train, cv = cv)\n",
    "    train_accuracy5 = model5.score(X_train, y_train)\n",
    "    test_accuracy5 = model5.score(X_test, y_test)\n",
    "\n",
    "    Linear_Results = {\n",
    "        'Model': 'Linear Regression',\n",
    "        'Train Accuracy': train_accuracy1,\n",
    "        'Test Accuracy': test_accuracy1,\n",
    "        'Cross-validation': cross_val_scores1.mean()}\n",
    "    RF_Results = {\n",
    "        'Model': 'RF',\n",
    "        'Train Accuracy': train_accuracy2,\n",
    "        'Test Accuracy': test_accuracy2,\n",
    "        'Cross-validation': cross_val_scores2.mean()}\n",
    "    KNN_Results = {\n",
    "        'Model': 'KNN',\n",
    "        'Train Accuracy': train_accuracy3,\n",
    "        'Test Accuracy': test_accuracy3,\n",
    "        'Cross-validation': cross_val_scores3.mean()}\n",
    "    DT_Results = {\n",
    "        'Model': 'DT',\n",
    "        'Train Accuracy': train_accuracy4,\n",
    "        'Test Accuracy': test_accuracy4,\n",
    "        'Cross-validation': cross_val_scores4.mean()}\n",
    "    SVR_Results = {\n",
    "        'Model': 'SVR',\n",
    "        'Train Accuracy': train_accuracy5,\n",
    "        'Test Accuracy': test_accuracy5,\n",
    "        'Cross-validation': cross_val_scores5.mean()}\n",
    "\n",
    "    result = []\n",
    "    result.append(Linear_Results)\n",
    "    result.append(RF_Results)\n",
    "    result.append(KNN_Results)\n",
    "    result.append(DT_Results)\n",
    "    result.append(SVR_Results)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define your method that generates a DataFrame\n",
    "def generate_dataframe():\n",
    "    # Declare the amount of dummy data to be created\n",
    "    num_of_samples = 1000\n",
    "\n",
    "    df = pd.DataFrame(GenerateRandomData(num_of_samples))\n",
    "    df = CleanAndCalculateDF(df)\n",
    "    df_Accuracy = pd.DataFrame(GetToModeling(df))\n",
    "    return df_Accuracy\n",
    "\n",
    "# Number of times to run the method\n",
    "n = 100\n",
    "\n",
    "# Initialize an empty DataFrame to store the concatenated results\n",
    "combined_df = pd.DataFrame()\n",
    "\n",
    "# Loop to run the method 'n' times and concatenate the DataFrames\n",
    "for _ in range(n):\n",
    "    df_iterate = generate_dataframe()\n",
    "    \n",
    "    # Concatenate the current DataFrame to the combined DataFrame\n",
    "    combined_df = pd.concat([combined_df, df_iterate], ignore_index=True)\n",
    "\n",
    "# Define the file path where you want to save the Excel file\n",
    "excel_file_path = 'output_data.xlsx'\n",
    "\n",
    "# Save the combined DataFrame to an Excel sheet\n",
    "combined_df.to_excel(excel_file_path, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
